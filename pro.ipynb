{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5a24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PyPDF2\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import tiktoken\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAPEDCYAXara0T52vCsd7aAb1_UdSaelfA\"\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68dc23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8d67d217df47808e835f15fc29902a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload = widgets.FileUpload(accept=\".pdf\", multiple=False)\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c878e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Loaded Successfully!\n",
      "\n",
      "WelcomeAirBed&BreakfastBook rooms with locals, rather than hotels.1\n",
      "This is a PowerPoint reproduction of an early AirBnB pitch deckvia Business Insider @http://www.businessinsider.com/airbnb-a-13-billion-dollar-startups-first-ever-pitch-deck-2011-9\n",
      "\n",
      "Problem2Priceis an important concern for customers booking travel online.Hotelsleave you disconnected from the city and its culture. No easy way exist\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_uploaded(upload_widget):\n",
    "    # If no file uploaded\n",
    "    if len(upload_widget.value) == 0:\n",
    "        raise ValueError(\"No file uploaded.\")\n",
    "\n",
    "    # VS Code Jupyter returns tuple instead of dict\n",
    "    uploaded_file = upload_widget.value[0]   # first uploaded file\n",
    "\n",
    "    # Extract bytes (PDF content)\n",
    "    pdf_bytes = uploaded_file['content']\n",
    "\n",
    "    # Read PDF pages\n",
    "    reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))\n",
    "\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            full_text += text + \"\\n\\n\"\n",
    "\n",
    "    return full_text\n",
    "\n",
    "\n",
    "# Test the extractor\n",
    "try:\n",
    "    pdf_text = extract_text_from_uploaded(upload)\n",
    "    print(\"PDF Loaded Successfully!\\n\")\n",
    "    print(pdf_text[:400])   # preview first 400 characters\n",
    "except Exception as e:\n",
    "    print(\"Upload Error:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca2b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Created: 2\n"
     ]
    }
   ],
   "source": [
    "def split_into_chunks(text, max_chars=2000):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), max_chars):\n",
    "        chunks.append(text[i:i+max_chars])\n",
    "    return chunks\n",
    "\n",
    "chunks = split_into_chunks(pdf_text)\n",
    "print(f\"Total Chunks Created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693e27f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Question: How we can improve our bussiness?\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question about the pitch deck: \").strip()\n",
    "\n",
    "if not question:\n",
    "    raise ValueError(\"Question cannot be empty!\")\n",
    "\n",
    "print(\"Your Question:\", question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0610fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_model_for_chunk(chunk_text, question):\n",
    "    prompt = f\"\"\"\n",
    "You are a startup pitch analyst.\n",
    "Answer the user's question based ONLY on the following text chunk.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Chunk:\n",
    "\\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "\n",
    "If answer not found, reply: \"No relevant info in this chunk.\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817f40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading chunk 1/2 ---\n",
      "Chunk Answer: No relevant info in this chunk.\n",
      "\n",
      "\n",
      "--- Reading chunk 2/2 ---\n",
      "Chunk Answer: No relevant info in this chunk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ask_model_for_chunk(chunk_text, question):\n",
    "    prompt = f\"\"\"\n",
    "You are a startup pitch analyst. \n",
    "Answer the user's question based ONLY on the following text chunk.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Chunk:\n",
    "\\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "\n",
    "If answer not found, reply: \"No relevant info in this chunk.\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "chunk_answers = []\n",
    "for i, c in enumerate(chunks):\n",
    "    print(f\"\\n--- Reading chunk {i+1}/{len(chunks)} ---\")\n",
    "    ans = ask_model_for_chunk(c, question)\n",
    "    print(\"Chunk Answer:\", ans[:150])\n",
    "    chunk_answers.append(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bfeed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== FINAL ANSWER ===\n",
      "\n",
      "Okay, I understand. You've provided me with multiple PDF extracts, but none of them contained relevant information. \n",
      "\n",
      "Therefore, my final answer is:\n",
      "\n",
      "**No relevant information was found in the provided PDF extracts.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_summary = \"\\n\".join(chunk_answers)\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a startup expert.\n",
    "Below are answers extracted from multiple PDF chunks.\n",
    "\n",
    "--- PDF EXTRACTS ---\n",
    "{full_summary}\n",
    "\n",
    "Combine them into one clean, structured final answer.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=synthesis_prompt\n",
    ")\n",
    "\n",
    "final_answer = response.text\n",
    "\n",
    "print(\"\\n\\n=== FINAL ANSWER ===\\n\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8913c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
